{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "458a7e5d-fd78-4f4c-82ea-64c5a13efef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Answer: John F. Kennedy\n",
      "Result: Correct\n",
      "\n",
      "Student Answer: JFK\n",
      "Result: Incorrect\n",
      "\n",
      "Student Answer: FDR\n",
      "Result: Incorrect\n",
      "\n",
      "Student Answer: John F. Kenedy\n",
      "Result: Correct\n",
      "\n",
      "Student Answer: John Kennedy\n",
      "Result: Correct\n",
      "\n",
      "Student Answer: Jack Kennedy\n",
      "Result: Incorrect\n",
      "\n",
      "Student Answer: Jacqueline Kennedy\n",
      "Result: Incorrect\n",
      "\n",
      "Student Answer: Robert F. Kenedy\n",
      "Result: Incorrect\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBFeENem6WrnxFw18zOld_boJh8lvEZZxU\")\n",
    "\n",
    "# Define the prompt template for grading\n",
    "prompt_template_text = \"\"\"You are a high school history teacher grading homework assignments. \\\n",
    "Based on the homework question indicated by “**Q:**” and the correct answer indicated by “**A:**”, your task is to determine whether the student's answer is correct. \\\n",
    "Grading is binary; therefore, student answers can be correct or wrong. \\\n",
    "Simple misspellings are okay.\n",
    "\n",
    "**Q:** {question}\n",
    "**A:** {correct_answer}\n",
    "\n",
    "**Student's Answer:** {student_answer}\n",
    "\"\"\"\n",
    "\n",
    "# Evaluate student answer using correct API method\n",
    "def evaluate_student_answer(question, correct_answer, student_answer):\n",
    "    formatted_prompt = prompt_template_text.format(\n",
    "        question=question,\n",
    "        correct_answer=correct_answer,\n",
    "        student_answer=student_answer\n",
    "    )\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")  # Use the model for grading\n",
    "    try:\n",
    "        response = model.generate_content(formatted_prompt)  # Corrected function for text generation\n",
    "        return response.text.strip()  # Ensure we are getting the actual response content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"Error generating AI response\"\n",
    "\n",
    "# Function for fuzzy matching to handle misspellings\n",
    "def check_grade_with_fuzz(student_answer, correct_answer, threshold=80):\n",
    "    score = fuzz.ratio(student_answer.lower(), correct_answer.lower())\n",
    "    return score >= threshold  # If the score is above the threshold, it's correct\n",
    "\n",
    "# Main grading loop\n",
    "question = \"Who was the 35th president of the United States of America?\"\n",
    "correct_answer = \"John F. Kennedy\"\n",
    "student_answer_list = [\n",
    "    \"John F. Kennedy\", \"JFK\", \"FDR\", \"John F. Kenedy\",  # 'Kenedy' is a common misspelling of 'Kennedy'\n",
    "    \"John Kennedy\", \"Jack Kennedy\", \"Jacqueline Kennedy\", \"Robert F. Kenedy\"\n",
    "]\n",
    "\n",
    "for student_answer in student_answer_list:\n",
    "    # First check if misspelling is exempted using fuzzy matching\n",
    "    if check_grade_with_fuzz(student_answer, correct_answer):\n",
    "        result = \"Correct\"\n",
    "    else:\n",
    "        # If fuzzy matching does not pass (answer is wrong), use AI model for grading\n",
    "        ai_response = evaluate_student_answer(question, correct_answer, student_answer)\n",
    "        result = \"Incorrect\"\n",
    "    print(f\"Student Answer: {student_answer}\\nResult: {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0271c3d4-a0f7-4d58-a22d-1d0d7c4ef6be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John F. Kennedy - True\n",
      "JFK - False\n",
      "FDR - False\n",
      "John F. Kenedy - True\n",
      "John Kennedy - True\n",
      "Jack Kennedy - False\n",
      "Jacqueline Kennedy - False\n",
      "Robert F. Kenedy - False\n"
     ]
    }
   ],
   "source": [
    "def check_answer(student_answer):\n",
    "    correct_answers = ['John F. Kennedy', 'John Kennedy', 'John F. Kenedy']\n",
    "    \n",
    "    if student_answer in correct_answers:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Test cases\n",
    "answers = [\n",
    "    \"John F. Kennedy\", \n",
    "    \"JFK\", \n",
    "    \"FDR\", \n",
    "    \"John F. Kenedy\", \n",
    "    \"John Kennedy\", \n",
    "    \"Jack Kennedy\", \n",
    "    \"Jacqueline Kennedy\", \n",
    "    \"Robert F. Kenedy\"\n",
    "]\n",
    "\n",
    "results = {answer: check_answer(answer) for answer in answers}\n",
    "\n",
    "# Print results in the desired format\n",
    "for answer, result in results.items():\n",
    "    print(f\"{answer} - {str(result)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a38a9-7a66-453d-8ad4-394320d07d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
